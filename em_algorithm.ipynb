{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        },
        "id": "0dzvPMKRz0ST",
        "outputId": "151b116e-dccb-4d04-f60d-f6cf14fdfcc7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting next iteration\n",
            "LL Dif:  inf\n",
            "Starting next iteration\n",
            "LL Dif:  461922.4716148921\n",
            "1.6131540547803525e-13\n",
            "Starting next iteration\n",
            "LL Dif:  inf\n",
            "Starting next iteration\n",
            "LL Dif:  4538312.2221486755\n",
            "-1.1426415369442111e-12\n",
            "Starting next iteration\n",
            "LL Dif:  inf\n",
            "Starting next iteration\n",
            "LL Dif:  293269.61402314843\n",
            "-2.4980018054066022e-14\n",
            "Starting next iteration\n",
            "LL Dif:  inf\n",
            "Starting next iteration\n",
            "LL Dif:  2556906.0655387407\n",
            "-2.250533093217655e-12\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from io_data import read_data\n",
        "from io_data import write_data\n",
        "\n",
        "\n",
        "def gaussianPDF(data, mean, covariance):\n",
        "    d = data.shape[1]\n",
        "    # Using gaussian pdf formula to ge denom and exponent then returning np.exp(exponent)/denom\n",
        "    denominator = np.sqrt(((2 * np.pi) ** d) * np.linalg.det(covariance))\n",
        "    x_minus_mean = data - mean\n",
        "    exponent = -(1 / 2) * np.sum(np.dot(x_minus_mean, np.linalg.inv(covariance)) * x_minus_mean, axis=1)\n",
        "\n",
        "    return np.exp(exponent) / denominator\n",
        "\n",
        "\n",
        "def logLikelihoodInitial(data, mean, covariance, weights):\n",
        "    d = data.shape[1]\n",
        "    n = data.shape[0]\n",
        "    k = weights.shape[0]\n",
        "    pdfs = np.zeros((n, k))\n",
        "\n",
        "    # Get all the pdfs for all the k's\n",
        "    for i in range(k):\n",
        "        pdfs[:, i] = weights[i] * gaussianPDF(data, mean[i], covariance[i])\n",
        "    # log likelihood is  equal to sum of the log of the sum of the pdfs\n",
        "    # aka the code below\n",
        "    log_likelihood = np.sum(np.log(np.sum(pdfs, axis=1)))\n",
        "    return log_likelihood\n",
        "\n",
        "\n",
        "def kmeansInitialization(data, k, initial):\n",
        "    # Choose two random centroids to start the kmeans initialization\n",
        "    n = data.shape[0]\n",
        "    d = data.shape[1]\n",
        "    mean = np.array(initial)\n",
        "\n",
        "    assignments = np.zeros(n, dtype=int)  # Used for filtering data\n",
        "\n",
        "    # Run it a few times to get it more accurate NOTE JK decreased it to one so it wouldnt overfit\n",
        "    iterations = 1\n",
        "\n",
        "    for i in range(iterations):\n",
        "        # Getting the minimum distances and assigning groups\n",
        "        distances = np.linalg.norm(data[:, np.newaxis, :] - mean, axis=2)\n",
        "        assignments = np.argmin(distances, axis=1)\n",
        "        for j in range(k):\n",
        "            mean[j, :] = np.mean(data[assignments == j, :], axis=0)\n",
        "\n",
        "    covariance = np.zeros((k, d, d))\n",
        "    for i in range(k):\n",
        "        # Get the variance of all the relevant data\n",
        "        variance_lst = data[assignments == i, :] - mean[i, :]\n",
        "        covariance[i, :, :] = np.dot(variance_lst.T, variance_lst) / (n - 1)\n",
        "\n",
        "    return mean, covariance, (np.array([len(data[assignments == 0]), len(data[assignments == 1])]) / n)\n",
        "\n",
        "\n",
        "def gmm(file_name, initial):\n",
        "    data, image = read_data(file_name, False)\n",
        "\n",
        "    img_data = np.array(data[:, 2:])\n",
        "\n",
        "    n = img_data.shape[0]\n",
        "    d = img_data.shape[1]\n",
        "    # Run k means for num_clusters to initialize covariances\n",
        "    # I need a mean/mu 2 by 3 (k by d). one average for each of the clusters\n",
        "    # covariance / sigma 2 by 3 by 3(k by d by d) one  3 by 3 matrix for each k\n",
        "    # p/ percentage assigned to k one n_k / n for each l\n",
        "    # count number of assigned to k\n",
        "    k = 2\n",
        "\n",
        "    mean, covariance, weights = kmeansInitialization(img_data, k, initial)\n",
        "\n",
        "    # Now get the initial log likelihood for comparison of convergence\n",
        "    prev_ll = -np.inf\n",
        "    log_likelihood = logLikelihoodInitial(img_data, mean, covariance, weights)\n",
        "\n",
        "    # Starting iterative loop until convergence\n",
        "    while True:\n",
        "        print('Starting next iteration\\nLL Dif: ', log_likelihood - prev_ll)\n",
        "        # e step get the responsibilities /soft assignments\n",
        "        responsibilities = np.zeros((n, k))  # Responsibilities will hold all the updated soft assignments\n",
        "        # go through all the samples with each weight\n",
        "\n",
        "        for i in range(k):\n",
        "            responsibilities[:, i] = weights[i] * gaussianPDF(img_data, mean[i], covariance[i])\n",
        "\n",
        "        for i in range(n):\n",
        "            responsibilities[i] /= np.sum(responsibilities[i])\n",
        "\n",
        "        # Onto the M step teehhee\n",
        "        for i in range(k):  # Iterate through each var for k\n",
        "            # update all the parameters by formulas\n",
        "            sum = np.sum(responsibilities[:, i])\n",
        "            weights[i] = sum / n\n",
        "            mean[i] = np.sum(responsibilities[:, i, np.newaxis] * img_data, axis=0) / sum\n",
        "            x_minus_mean = img_data - mean[i]\n",
        "            covariance[i] = np.dot(responsibilities[:, i] * x_minus_mean.T, x_minus_mean) / sum\n",
        "\n",
        "        prev_ll = log_likelihood\n",
        "        log_likelihood = np.sum(np.log(np.sum(responsibilities, axis=1)))\n",
        "        if log_likelihood - prev_ll < 1e-6:\n",
        "            print(log_likelihood - prev_ll)\n",
        "            break\n",
        "\n",
        "    get_labels = np.argmax(responsibilities, axis=1)\n",
        "    data_out1, data_out2 = getImageData(get_labels, data, False)\n",
        "    data_mask, d = getImageData(get_labels, data)\n",
        "    return data_out1, data_out2, data_mask\n",
        "\n",
        "\n",
        "def getImageData(labels, data, mask=True):\n",
        "    white = (100, 0, 0)\n",
        "    black = (0, 0, 0)\n",
        "    if mask:\n",
        "        for i in range(len(data)):\n",
        "            if labels[i]:\n",
        "                data[i, 2] = white[0]\n",
        "                data[i, 3] = white[1]\n",
        "                data[i, 4] = white[2]\n",
        "            else:\n",
        "                data[i, 2] = black[0]\n",
        "                data[i, 3] = black[1]\n",
        "                data[i, 4] = black[2]\n",
        "        return data, data\n",
        "    else:\n",
        "        data1 = data.copy()\n",
        "        data0 = data.copy()\n",
        "        for i in range(len(data)):\n",
        "            if labels[i]:\n",
        "                data0[i, 2] = black[0]\n",
        "                data0[i, 3] = black[1]\n",
        "                data0[i, 4] = black[2]\n",
        "            else:\n",
        "                data1[i, 2] = black[0]\n",
        "                data1[i, 3] = black[1]\n",
        "                data1[i, 4] = black[2]\n",
        "        return data0, data1\n",
        "\n",
        "\n",
        "def __main__():\n",
        "    data_names = ['cow', 'fox', 'owl', 'zebra']\n",
        "    initials = [[[50, 0, 0], [46, -22, 40]],\n",
        "               [[46, 13, 34], [46, -22, 40]],\n",
        "               [[95, -1, 3], [70, 2, 22]],\n",
        "               [[50, 0, 0], [64, -20, 46]]\n",
        "               ]\n",
        "    for i in range(len(data_names)):\n",
        "\n",
        "        out1, out2, out_mask = gmm('data/' + data_names[i] + '.txt', initials[i])\n",
        "\n",
        "        write_data(out1, 'data/out1_' + data_names[i] + '.txt')\n",
        "        write_data(out2, 'data/out2_' + data_names[i] + '.txt')\n",
        "        write_data(out_mask, 'data/outmask_' + data_names[i] + '.txt')\n",
        "\n",
        "        data, image = read_data(\"data/outmask_\" + data_names[i] + \".txt\", False, False, True, \"data/mask_\" + data_names[i] + \".jpg\")\n",
        "        data, image = read_data('data/out2_' + data_names[i] + '.txt', False, False, True, \"data/out1_\" + data_names[i] + \".jpg\")\n",
        "        data, image = read_data('data/out1_' + data_names[i] + '.txt', False, False, True, \"data/out2_\" + data_names[i] + \".jpg\")\n",
        "\n",
        "\n",
        "\n",
        "__main__()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
